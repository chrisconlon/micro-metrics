\documentclass[11pt, aspectratio=169]{beamer}
\usefonttheme[onlymath]{serif}
% Autocompletions:
% wit: begin wideitemize
% bit: begin itemize
  % { "trigger": "it", "contents": "\\textit{$1}$0"},
  %               { "trigger": "bf", "contents": "\\textbf{$1}$0"},
  %               { "trigger": "em", "contents": "\\emph{$1}$0"},
  %               { "trigger": "tt", "contents": "\\texttt{$1}$0"},
  %               { "trigger": "un", "contents": "\\underline{$1}$0"},

  %               { "trigger": "bs", "contents": "\\bigskip"},
  %               { "trigger": "ms", "contents": "\\medskip"},
  %               { "trigger": "ss", "contents": "\\smallskip"},

  %               { "trigger": "use", "contents": "\\usepackage"},
        
                % { "trigger": "beq", "contents": "\\[\n$0\n\\]"},               
  %               { "trigger": "beqn", "contents": "\\begin{equation}\n$0\n\\end{equation}\n"},


\usepackage{pgfpages}
% These slides also contain speaker notes. You can print just the slides,
% just the notes, or both, depending on the setting below. Comment out the want
% you want.
\setbeameroption{show notes}
\setbeameroption{hide notes} % Only slide
%\setbeameroption{show only notes} % Only notes
%\setbeameroption{show notes on second screen=right} % Both

\usepackage{helvet}
\usepackage[default]{lato}
\usepackage{array}


\usepackage{tikz}
\usepackage{verbatim}
\setbeamertemplate{note page}{\pagecolor{yellow!5}\insertnote}
\usetikzlibrary{positioning}
% \usetikzlibrary{snakes}
\usetikzlibrary{decorations}
\usetikzlibrary{calc}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{matrix,shapes,arrows,fit,tikzmark}
\usepackage{amsmath}
\usepackage{mathpazo}
\usepackage{hyperref}
\usepackage{lipsum}
\usepackage{multimedia}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{dcolumn}
% \usepackage{enumitem}
\usepackage{bbm}
\newcolumntype{d}[0]{D{.}{.}{5}}

\newcommand{\Skip}{\vspace{1em}}
\newcommand{\Squish}{\vspace{-1em}}


\usepackage{changepage}
\usepackage{appendixnumberbeamer}
\newcommand{\beginbackup}{
   \newcounter{framenumbervorappendix}
   \setcounter{framenumbervorappendix}{\value{framenumber}}
   \setbeamertemplate{footline}
   {
     \leavevmode%
     \hline
     box{%
       \begin{beamercolorbox}[wd=\paperwidth,ht=2.25ex,dp=1ex,right]{footlinecolor}%
%         \insertframenumber  \hspace*{2ex} 
       \end{beamercolorbox}}%
     \vskip0pt%
   }
 }
\newcommand{\backupend}{
   \addtocounter{framenumbervorappendix}{-\value{framenumber}}
   \addtocounter{framenumber}{\value{framenumbervorappendix}} 
}


\usepackage{graphicx}
\usepackage[space]{grffile}
\usepackage{booktabs}

% These are my colors -- there are many like them, but these ones are mine.
\definecolor{blue}{RGB}{0,114,178}
\definecolor{red}{RGB}{213,94,0}
\definecolor{yellow}{RGB}{240,228,66}
\definecolor{green}{RGB}{0,158,115}

\hypersetup{
  colorlinks=false,
  linkbordercolor = {white},
  linkcolor = {blue}
}


%% I use a beige off white for my background
\definecolor{MyBackground}{RGB}{255,253,218}

%% Uncomment this if you want to change the background color to something else
%\setbeamercolor{background canvas}{bg=MyBackground}

%% Change the bg color to adjust your transition slide background color!
\newenvironment{transitionframe}{
  \setbeamercolor{background canvas}{bg=yellow}
  \begin{frame}}{
    \end{frame}
}

\setbeamercolor{frametitle}{fg=blue}
\setbeamercolor{title}{fg=black}
\setbeamertemplate{footline}[frame number]
\setbeamertemplate{navigation symbols}{} 
\setbeamertemplate{itemize items}{-}
\setbeamercolor{itemize item}{fg=blue}
\setbeamercolor{itemize subitem}{fg=blue}
\setbeamercolor{enumerate item}{fg=blue}
\setbeamercolor{enumerate subitem}{fg=blue}
\setbeamercolor{button}{bg=MyBackground,fg=blue,}



% If you like road maps, rather than having clutter at the top, have a roadmap show up at the end of each section 
% (and after your introduction)
% Uncomment this is if you want the roadmap!
\AtBeginSection[]
{
   \begin{frame}
       \frametitle{Roadmap of Talk}
       \tableofcontents[currentsection]
   \end{frame}
}
\setbeamercolor{section in toc}{fg=blue}
\setbeamercolor{subsection in toc}{fg=red}
\setbeamersize{text margin left=1em,text margin right=1em} 

\newenvironment{wideitemize}{\itemize\addtolength{\itemsep}{10pt}}{\enditemize}
\newenvironment{wideenumerate}{\enumerate\addtolength{\itemsep}{10pt}}{\endenumerate}
\newenvironment{widedescription}{\description\addtolength{\itemsep}{10pt}}{\enddescription}






\title[]{\textcolor{blue}{Markov Chain Monte Carlo}}

\author[CM]{Charlie Murry}
\institute{Boston College}

% \author[PGP]{}
% \institute[FRBNY]{\small{\begin{tabular}{c c c}
% Author A &&  Paul Goldsmith-Pinkham  \\
% Somewhere Fancy && FRBNY \\ \\

% Author C && Author D   \\
% \multicolumn{3}{c}{Somewhere Fancy} \\
% \end{tabular}}}

\date{\today}


\begin{document}

%%% TIKZ STUFF
\tikzset{   
        every picture/.style={remember picture,baseline},
        every node/.style={anchor=base,align=center,outer sep=1.5pt},
        every path/.style={thick},
        }
\newcommand\marktopleft[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-#1-a) at (-.3em,.3em) {};%
}
\newcommand\markbottomright[2]{%
    \tikz[overlay,remember picture] 
        \node (marker-#1-b) at (0em,0em) {};%
}
\tikzstyle{every picture}+=[remember picture] 
\tikzstyle{mybox} =[draw=black, very thick, rectangle, inner sep=10pt, inner ysep=20pt]
\tikzstyle{fancytitle} =[draw=black,fill=red, text=white]
%%%% END TIKZ STUFF

% Title Slide (will go at the bottom of title slide)
\begin{frame}
\maketitle
  % \centering The views expressed do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System.
\end{frame}

% INTRO
% \section[intro]{Introduction} % (fold)
% \label{sec:introduction}

\begin{frame}[c]\frametitle{Overview of Bayesian Estimation}
    
\begin{itemize}
    \item We wish to know about unkown parameter $\theta^0\in R^N$
    \item We have data $y$, and $L(y|\theta)$ is the likelihood of $y$ given that $\theta = \theta^0$. 
\end{itemize}    

\textbf{Frequentist}
\begin{itemize}
	\item Derive an estimator (MLE) and analyze statistical properties of that estimator
	$$ \hat{\theta} = \max_{\theta} L(y | \theta).$$
\end{itemize}

\textbf{Bayesian}
\begin{itemize}
	\item Start with a prior belief, $p(\theta)$.
	\item Use data to update their belief  to posterior using Bayes Rule
	$$\pi(\theta | y) = \frac{L(y | \theta) p(\theta)}{f(y)}$$ 
where $f(y) = \int L(y|\theta)\pi(\theta) d\theta$ is the marginal distribution of $y$. 

\end{itemize}

\end{frame}


\begin{frame}[c]\frametitle{Bayes Rule}
    
$$\pi(\theta | y) = \frac{L(y | \theta) p(\theta)}{f(y)}$$ 

is just

$$Pr(A | B) = \frac{Pr(A \cap B)}{Pr(B)} = \frac{Pr(B|A) Pr(A)}{Pr(B)}.$$

\end{frame}


\begin{frame}[c]\frametitle{Bayesian Estimation Overview}
    
\begin{wideitemize}
    \item Outcome of estimation is $\rho(\cdot)$: summarizes everything we know about where $\theta$ is.
    \item Typically report moments of $\rho$.
    \item $\rho$ is typically not tractable. How do we report moments from something that is not tractable. 
\end{wideitemize}    

\vspace{1em}
\textbf{Good:} No need to solve complex optimization problem.

\vspace{1em}
\textbf{Bad:} By construction there is a complex integral.

\end{frame}


\begin{frame}[t]\frametitle{Tractable Example I}
\framesubtitle{Cameron and Trivedi, p422}    

Nothing about a posterior per se that requires MCMC.


\begin{wideitemize}
	\item Suppose you observe $N$ draws from 
a normal distribution with mean $\theta$ and variance $\sigma^2$, e.g., 
$$y_i \sim N(\theta, \sigma^2).$$ 
	\item $\sigma^2$ is known, but you want to estimate $\theta$.
	\item A frequentist might use maximum likelihood estimation. The likelihood is:
\begin{align*}
L(y|\theta) &= \prod_{i=1}^N (2\pi \sigma^2)^{- \frac{1}{2} } \exp \left\{ - \frac{(y_i - \theta)^2}{2 \sigma^2} \right\} \\
&= (2\pi \sigma^2)^{- \frac{N}{2} } \exp  \left\{ - \sum_{i=1}^N \frac{(y_i - \theta)^2}{2 \sigma^2} \right\} \\
% & \propto  \exp  \left\{ \frac{-1}{2 \sigma^2}  \sum_{i=1}^N (y_i - \bar{y} +\bar{y} - \theta)^2 \right\} \\
% &  \propto  \exp  \left\{ - \frac{1}{2 \sigma^2}  \sum_{i=1}^N (y_i - \bar{y})^2 \right\} \exp  \left\{ - \frac{N}{2 \sigma^2} (\bar{y} - \theta)^2 \right\} \\
&  \propto  \exp  \left\{ - \frac{N}{2 \sigma^2}   (\bar{y} - \theta)^2 \right\} \\
\end{align*}
\end{wideitemize}


\end{frame}


\begin{frame}[t]\frametitle{Tractable Example II}
\framesubtitle{Cameron and Trivedi, p422}    

\begin{wideitemize}
	\item Clearly this is maximized at $\bar{y}$, which is the MLE estimate.
	\item Just compute the average from your data. 
\end{wideitemize}

\textbf{Bayesian}
\begin{wideitemize}
	\item Define prior belief, $\theta$.
	\item Suppose that belief is normally distributed with mean $\mu$ and variance $\tau^2$
	\item Prior density:
	$$p(\theta) =  (2\pi \tau^2)^{- \frac{1}{2} } \exp \left\{ - \frac{(\theta - \mu)^2}{2 \tau^2} \right\}.$$

\end{wideitemize}

\end{frame}


\begin{frame}[t]\frametitle{Tractable Example III}
\framesubtitle{Cameron and Trivedi, p422}    

Following Bayes Rule, the Posterior is proportional to:

\begin{align*}
\pi(\theta | y) & \propto L(y|\theta) p(\theta) \\
& \propto \exp  \left\{ - \frac{N}{2 \sigma^2}   (\bar{y} - \theta)^2 \right\} \exp \left\{ - \frac{(\theta - \mu)^2}{2 \tau^2} \right\} \\
% & \propto \exp \left\{ - \frac{1}{2} \left[ \frac{  (\bar{y} - \theta)^2 }{N^{-1} \sigma^2} + \frac{(\theta - \mu)^2}{ \tau^2 } \right] \right\} \\
& \propto  \exp \left\{ - \frac{1}{2} \left[ \frac{ (\theta - \tilde{\mu})^2 }{\tilde{\tau}^2} \right] \right\}
\end{align*} 
Where,  
$$\tilde{\mu} = \tilde{\tau}^2 \left( \frac{N}{\sigma^2} \bar{y} + \frac{1}{\tau^2} \mu \right)$$
$$\tilde{\tau}^2 = \left(  \frac{N}{\sigma^2} + \frac{1}{\tau^2} \right)^{-1} $$


\end{frame}


\begin{frame}[c]\frametitle{Tractable Example III}
\framesubtitle{Cameron and Trivedi, p422}    

\begin{wideitemize}
	\item The final line is a normal kernel (just complete the square :) ). 
	\item The posterior is normally distributed with mean $\tilde{\mu}$ which is a weighted sum of $y$ and the prior mean $\mu$.
	\item Since this posterior is normal, it is easy for us to compute the moments.
	\item Mean of posterior goes to $\bar{y}$ as $N\rightarrow\infty$. 
	\item But computing moments of even slightly messier posteriors will require complex integration that we will tackle via simulation. 
\end{wideitemize}


\end{frame}


\begin{frame}[c]\frametitle{Review of Monte Carlo Integration}
    
The point of monte carlo integration is to use draws from a distribution to calculate the moments of $\rho(\theta|y)$. If $\rho(\cdot)$ is ``easy'' to draw from (say, uniform or normal) than we can use traditional monte carlo integration techniques: 
$$E[m(\theta)] = \int_\Theta m(\theta) \rho(\theta|y) d\theta \approx \frac{1}{S} \sum_{s=1}^S m(\theta_s)$$
\begin{itemize}
\item $m(\cdot)$ is an arbitrary function, say identity if we want the mean. We need to assume this expectation exists (of course).  
\item $\theta_s$ is a draw from $\rho(\theta|y)$. 
\end{itemize}

However, this isn't helpful if we don't know how to generate draws from $\rho(\cdot)$ and if we did, we could probably just integrate it directly. 


\end{frame}



\begin{frame}[c]\frametitle{Markov Chain Monte Carlo}
 
MCMC uses draws from a \alert{Markov Chain}, instead of i.i.d. draws from some known distribution. 

\vspace{.5em} 
Use MCMC when:
\begin{itemize}
\item Analytic solutions aren't tractable. 
\item IID sampling doesn't give adequate coverage (perhaps dimension is too high or good approximation of $\rho$ is unknown). 
\end{itemize}


The goal becomes constructing an \alert{ergodic} Markov Chain $F$ (so that the \alert{stationary distribution} exists) such that the stationary
distribution is exactly $\rho$.  If we do this then we can generate moments of $\rho$ from

$$ E[m(\theta)] \approx \frac{1}{S} \sum_{i=1}^S m(\theta_i) $$
where $\theta_i \sim F(\cdot | \theta_{i-1})$. 

\end{frame}


\begin{frame}[c]\frametitle{English, please?}
    

ergodic: statistical properties can be deduced from a single, sufficiently long, random sample of the process. 

\vspace{2em}
note ergodic: a process that changes erratically at an inconsistent rate

\vspace{2em}
stationary distribution: probability distribution that remains unchanged in the Markov chain as time progresses. (The transition matrix of a discrete processes remains constant)

\end{frame}


\begin{frame}[c]\frametitle{Markov Chain Theory}    

Let the state space for $\theta$ be discrete, $\Theta = \{\theta^{(1)}, \ldots, \theta^{(K)} \}$.\footnote{Of course this isn't reasonable for estimation but it allows me to 
skip over a bunch of measure theory.} 

\vspace{2em}
Let our chain be defined by
$$P(\theta_{r+1} = \theta^{(j)} | \theta_r = \theta^{(i)}) = p_{ij} $$
So the Markov transition matrix is, 
$$P = \begin{bmatrix} p_{11} & p_{12} & \ldots & p_{1K} \\
 p_{21} & p_{22} & \ldots&  p_{2K} \\
 \vdots & & & \vdots \\
 p_{K1} & p_{K2} & \ldots&  p_{KK} \end{bmatrix}$$

\end{frame}



\begin{frame}[c]\frametitle{MC Theory: Stationarity}
    

Let $\pi_0$ be an initial distribution over states (a $1 \times K$ vector). Then the distribution over states after 1 period will be:
$$Pr( \theta_1 = \theta^{(j)}) = \sum_{i=1}^K Pr(\theta_0 = \theta^{(i)}) p_{ij} = \sum_{i=1}^K \pi_{0i} p_{ij} $$
Or in matrix notation for the entire distribution, 
$$\pi_1 = \pi_0 P$$

\vspace{.5em}
If for all $i,j$: $p_{ij} > 0$, then every state will be visited infinitely often.

\vspace{1em}
A stationary distribution exists and is unique:
$$ \lim_{r \rightarrow \infty} \pi_0P^r = \pi$$
for any $\pi_0$ and of course, 
$$ \pi = \pi P $$
The stationary distribution $\pi$ is sometimes called the invariant distribution. 

\end{frame}


\begin{frame}[c]\frametitle{Time Reversibility}
    
\begin{definition} A chain is time reversible with respect to $\pi$ if it has the same behavior backwards and forwards starting from $\pi$. That is if the chance of seeing a transition from $i$ to $j$ is the same as seeing a transition from $j$ to $i$: 
$$ \pi_i p_{ij} = \pi_j p_{ji}$$
\end{definition}


\end{frame}



\begin{frame}[c]\frametitle{MCMC: Gibbs Sampling}

Construct Markov chain by ``cycling'' through conditional distributions related to $\pi$. 

\begin{wideitemize}
	\item Let $\theta = [\theta_1, \theta_2]'$ with posterior density $p(\theta_1, \theta_2)$.
	\item \emph{If the conditional densities are known}, then alternating sequential draws from $p(\theta_1 \mid \theta_2)$ and $p(\theta_2 \mid \theta_1)$ converge to $p(\theta_1, \theta_2)$.
\end{wideitemize}


\end{frame}


\begin{frame}[c]\frametitle{Gibbs Example: Probit}
\framesubtitle{Using Data Augmentation}
    
Model: 
$$ z_i = x_i \beta + \epsilon_i $$
$$ y_i = \begin{cases} 0 & z_i \leq 0 \\ 1 & z_i > 0 \end{cases}$$
$$ \epsilon_i \sim N(0, 1)$$
We observe a random sample of $(y_i, x_i)$ and want to estimate $\beta$. \\

\vspace{1em}
Suppose we have a prior $\beta \sim N(\bar{\beta}, A^{-1})$. If we observed $z_i$ then the posterior would be normal (normal is the \emph{conjugate prior} of normal). 

\vspace{1em}
However, when $z$ is unobserved there is no simple conjugate prior.  

\vspace{1em}
Instead, we can use an ``augmentation step'' by employing a Gibbs sampler with two blocks $(z_i, \beta)$, the second step uses draws of $z$ and the normal conjugate prior.

\end{frame}


\begin{frame}[c]\frametitle{Probit Example | Algorithm}
    
\begin{enumerate}
\item Given $\beta_{r-1}$, draw $z_i$ by drawing from a truncated normal: 
$$ z_{i, r} | \beta_{r-1}, y_i, x_i \sim \mbox{TruncatedNormal}_a^b(-x_i \beta_{r-1}, 1) $$
Where bounds are $a = 0, b = \infty$ if $y_i = 1$ and $a = -\infty, b = 0$ if $y_i = 0$
\item Draw $\beta_r | z_{i,r}, x_i$ from the posterior of a regression of $z$ on $x$:
$$\beta_r \sim N(\tilde{\beta}, (X'X + A)^{-1})$$
where $\tilde{\beta} = (X'X + A)^{-1}(X'z + A\bar{\beta})$. 
\item After many draws, we have a sample of $\beta_r$ which we use as draws from the stationary distribution. 
\end{enumerate}    

\end{frame}


\begin{frame}[c]\frametitle{Example | Multivariate Normal}
    
The file {\tt simpleGibbs.m} implements Gibbs sampling to draw from a bivariate normal: 

$$(y_1, y_2)' \sim N\left( \begin{pmatrix} \mu_1 \\ \mu_2 \end{pmatrix}, \begin{pmatrix} \sigma_1^2 & \rho \sigma_1 \sigma_2 \\ \rho \sigma_1 \sigma_2 & \sigma_2^2 \end{pmatrix} \right) $$

This trivially implies conditional distributions: 
$$y_1 | y_2 \sim N(\mu_1 + \rho \frac{\sigma_1}{\sigma_2}(y_2 - \mu_2), \sigma_1^2(1 - \rho^2))$$

% Let's go through the code and see how it works: 
% Items to consider: 
% \begin{itemize}
% \item See what happens when you start from (50, 50). 
% \item See what happens when you raise $\rho$ to .95. 
% \item Choosing a burn-in period. 
% \item The relationship between correlation and convergence. 
% \item Checking autocorrelation of the chain: 
% $$s_{\theta_i}(k) = \frac{ \sum_{r = k+1}^R (\theta_r - \bar{\theta})(\theta_{r-k} - \bar{\theta})}{ \sum_r=1^R  (\theta_r - \bar{\theta})^2} $$
% \item Can also check for convergence by computing moments from different subsamples of the chain and making sure they are robust.
% \end{itemize}    


\end{frame}


\end{document}

